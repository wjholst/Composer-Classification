{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/wjholst/composer-classification-build-model?scriptVersionId=101236165\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Introduction\n-----","metadata":{}},{"cell_type":"markdown","source":"## Acknowledgments\n- [ðŸŽ¼ Music generation based on classics ðŸŽ¼](https://www.kaggle.com/smogomes/music-generation-based-on-classics)\n- [Beginner's Guide to Audio Data](https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-audio-data)\n- [Music Generation: LSTM ðŸŽ¹](https://www.kaggle.com/karnikakapoor/music-generation-lstm)","metadata":{}},{"cell_type":"markdown","source":"## Results History\n\n### Version 50 Results\n\nThis model relaxed the early stopping to a patience factor of 10 and increased the epochs to 100. Overall accuracy finally hit 0.80. There may not be much room for improvement without additional data.\n\nFurther improvements include use of a pre-trained resnet model and data augmentation.\n__________________________________________________________\n\n```\nConfusion for Ensemble Prediction\n              precision    recall  f1-score   support\n\n      mozart       0.87      0.83      0.85       652\n    schubert       0.82      0.63      0.71       727\n       grieg       0.89      0.91      0.90       263\n       haydn       0.82      0.92      0.87       489\n mendelssohn       0.71      0.90      0.80       263\n      chopin       0.71      0.79      0.74       458\n\n    accuracy                           0.80      2852\n   macro avg       0.80      0.83      0.81      2852\nweighted avg       0.81      0.80      0.80      2852\n```\n\n### Version 49 Results\n\nThere were no improvements but training time slowed down. The batch size should be reset to 32.\n\n### Version 47 Results\n\nThis model relaxed the early stopping to a patience factor of 10 and increased the epochs to 70. Overall accuracy finally hit 0.77. There may not be much room for improvement without additional data.\n\nNext run will reduce batch size to something close to 2x the number of classes.\n__________________________________________________________\n\n```\nConfusion for Ensemble Prediction\n              precision    recall  f1-score   support\n\n      mozart       0.81      0.79      0.80       652\n    schubert       0.79      0.60      0.68       727\n       grieg       0.83      0.92      0.87       263\n       haydn       0.81      0.89      0.84       489\n mendelssohn       0.66      0.87      0.75       263\n      chopin       0.70      0.75      0.72       458\n\n    accuracy                           0.77      2852\n   macro avg       0.77      0.80      0.78      2852\nweighted avg       0.77      0.77      0.77      2852\n\n```\n### Version 46 Results\n\nThis model relaxed the early stopping and increased the epochs to 50. Overall accuracy finally hit 0.70. The early stopping probably took 2 or 3 % away.\n\nAt 50 the model validation accuracy was still increasing so increasing the epochs will probably add another percent or 2 in performance accuracy.\n__________________________________________________________\n```\nConfusion for Ensemble Prediction\n              precision    recall  f1-score   support\n\n      mozart       0.81      0.71      0.75       652\n    schubert       0.74      0.50      0.60       727\n       grieg       0.86      0.79      0.83       263\n       haydn       0.71      0.87      0.78       489\n mendelssohn       0.51      0.92      0.65       263\n      chopin       0.66      0.68      0.67       458\n\n    accuracy                           0.70      2852\n   macro avg       0.71      0.74      0.71      2852\nweighted avg       0.73      0.70      0.70      2852\n```\n\n### Version 45 Results\n\nThis model reduced the filters to 32 and increased the epochs to 35. At 35 the model validation accuracy was still increasing so increasing the epochs will probably add another percent or 2 in performance accuracy.\n__________________________________________________________\n```\nConfusion for Ensemble Prediction\n              precision    recall  f1-score   support\n\n      mozart       0.79      0.68      0.73       652\n    schubert       0.78      0.45      0.57       727\n       grieg       0.70      0.90      0.78       263\n       haydn       0.73      0.83      0.78       489\n mendelssohn       0.50      0.91      0.65       263\n      chopin       0.62      0.68      0.65       458\n\n    accuracy                           0.69      2852\n   macro avg       0.69      0.74      0.69      2852\nweighted avg       0.72      0.69      0.68      2852\n```\n\n### Version 44 Results\n\n__________________________________________________________\n\nThis model reduced the input size to 128x128. The overall accuracy and f1 scores were very close to the prior model which used 216x256, so there was virtually no loss of performance.\n\n```Confusion for Ensemble Prediction\n              precision    recall  f1-score   support\n\n      mozart       0.70      0.66      0.68       652\n    schubert       0.51      0.55      0.53       727\n       grieg       0.59      0.38      0.46       263\n       haydn       0.62      0.70      0.66       489\n mendelssohn       0.42      0.40      0.41       263\n      chopin       0.55      0.58      0.57       458\n\n    accuracy                           0.58      2852\n   macro avg       0.57      0.54      0.55      2852\nweighted avg       0.58      0.58      0.57      2852\n```\n\n### Version 41 Results\n\nBoth filter parameters were increased to 8. This made no difference in the accuracy but it took about 50% longer to train.\nIt is time to replace with a simple stacked CNN network. I will also reduce the input size to 192x192.\n\n__________________________________________________________\n```\nConfusion for Ensemble Prediction\n              precision    recall  f1-score   support\n\n      mozart       0.69      0.63      0.66       652\n    schubert       0.46      0.58      0.52       727\n       grieg       0.65      0.37      0.47       263\n       haydn       0.62      0.68      0.65       489\n mendelssohn       0.46      0.44      0.45       263\n      chopin       0.56      0.49      0.52       458\n\n    accuracy                           0.56      2852\n   macro avg       0.58      0.53      0.55      2852\nweighted avg       0.58      0.56      0.56      2852\n```\n\n### Version 41 Results\n__________________________________________________________\n\nPer discussion with Andy, tried changing the number of filters from 5 and 16 to 64 and 64. This generated 56M parameters. It took 440s to run 1 epoch, so the process was probably too slow. After 2, accuracy was 0.35 train, 0.39 validation. In the prior model it took 7 epochs to reach this same level in around 250 seconds. Before this model is replaced, will try with a smaller adjustment to filters.\n\n### Version 36 Results\n__________________________________________________________\n\nWe added early stopping L2 regulation, which reduced the overfitting dramatically. This version record 0.58 accuracy with good prediction across all 6 composers.  Next step will be to add additional augmented data.\n\n```\nConfusion for Ensemble Prediction\n              precision    recall  f1-score   support\n\n      mozart       0.65      0.70      0.68       652\n    schubert       0.51      0.57      0.54       727\n       grieg       0.60      0.44      0.51       263\n       haydn       0.66      0.69      0.67       489\n mendelssohn       0.45      0.48      0.47       263\n      chopin       0.56      0.44      0.49       458\n\n    accuracy                           0.58      2852\n   macro avg       0.57      0.55      0.56      2852\nweighted avg       0.58      0.58      0.58      2852\n\n```\n\n### Version 32 Results\n__________________________________________________________\n\nThe run with unscaled data produced very poor accuracy of only 0.25. This effort was abandoned.\n\nNext effort is to build an ensemble predictor.\n\n### Version 31 Results\n\n__________________________________________________________\n\n* 30 epochs\n* 3 way validation\n* Middle layers of NN used\n* Use of .08 Gaussian noise at higher level in model\n* Introduction of about 1500 new samples from Grieg, Mendelssohn, and Haydn.\n\nThe accuracy improved to 0.53, with most improvement in the newly added sampled composers. For the first time the macro average was over 0.5. We are still overfitting the training data.\n\nThings to try:\n\n* Calculation of a combined prediction my taking the sum of the 3 predictions and taking the max of the summed values.\n* Try with un-scaled data\n__________________________________________________________\n\n\n```\nResults for model 0\n              precision    recall  f1-score   support\n\n      mozart       0.60      0.69      0.64       652\n    schubert       0.46      0.70      0.55       727\n       grieg       0.45      0.21      0.29       263\n       haydn       0.63      0.53      0.58       489\n mendelssohn       0.42      0.24      0.31       263\n      chopin       0.55      0.35      0.43       458\n\n    accuracy                           0.53      2852\n   macro avg       0.52      0.46      0.47      2852\nweighted avg       0.53      0.53      0.51      2852\n\n```\n\n### Version 30 Results\n\n__________________________________________________________\nAfter adding about 1000 new samples, the results of the confusion matrix were confused. This was due to an incorrect parameter placement in on of the confusion reports. The results were not valid and have not been valid for several iterations. Next run corrects that.\n\n### Version 29 Results\n\n__________________________________________________________\n\n* 35 epochs\n* 3 way validation\n* Middle layers of NN used\n* Introduction of less Gaussian noise at higher level in model\n\nThis model did not perform any better than any other. Next version will use the new dataset with about 1000 more samples.\n\n```\n\nResults for model 2\n              precision    recall  f1-score   support\n\n      mozart       0.64      0.69      0.67       651\n    schubert       0.49      0.62      0.55       727\n       grieg       0.35      0.08      0.13       133\n       haydn       0.40      0.37      0.38       246\n mendelssohn       0.36      0.06      0.10       133\n      chopin       0.51      0.47      0.49       458\n\n    accuracy                           0.53      2348\n   macro avg       0.46      0.38      0.39      2348\nweighted avg       0.51      0.53      0.50      2348\n```\n\n### Version 28 Results\n\n__________________________________________________________\n\n* 25 epochs\n* 3 way validation\n* Middle layers of NN used\n* Introduction of less Gaussian noise at higher level in model\n\nThis version obtained a slightly higher accuracy than our best model. It still overtrained, but not as bad as the prior. We will plan one more iteration before we increase the training set size. In addition we will add 10 more iterations and increase the noise from .04 to .08.\n\n```\nResults for model 0\n              precision    recall  f1-score   support\n\n      mozart       0.72      0.57      0.64       651\n    schubert       0.47      0.69      0.56       727\n       grieg       0.23      0.34      0.27       133\n       haydn       0.44      0.35      0.39       246\n mendelssohn       0.20      0.22      0.21       133\n      chopin       0.59      0.29      0.39       458\n\n    accuracy                           0.50      2348\n   macro avg       0.44      0.41      0.41      2348\nweighted avg       0.53      0.50      0.49      2348\n\n```\n\n### Version 26 Results\n\n__________________________________________________________\n\n* 25 epochs\n* 3 way validation\n* Middle layers of NN used\n* Introduction of Gaussian noise\n\nThis version introduced Gaussian noice on a hidden layer. The result was that the model did not overfit, which was the goal, but it also did not perform very well, only 0.47 accuracy. Perhaps 10% noise was too much. And perhaps the noise should be at the top layer.\n```\nResults for model 1\n              precision    recall  f1-score   support\n\n      mozart       0.72      0.57      0.64       651\n    schubert       0.45      0.43      0.44       727\n       grieg       0.19      0.24      0.21       133\n       haydn       0.41      0.41      0.41       246\n mendelssohn       0.22      0.44      0.30       133\n      chopin       0.48      0.48      0.48       458\n\n    accuracy                           0.47      2348\n   macro avg       0.41      0.43      0.41      2348\nweighted avg       0.50      0.47      0.48      2348\n```\n\n### Version 22 Results\n\n__________________________________________________________\n\n* 25 epochs\n* 3 way validation\n* Middle layers of NN used\n\nBecause the prior model was overfitting, I reduced the epochs to 25. The accuracy did not go down appreciably; it is still 0.52. \n\nThere are several things that should be tried:\n\n* Additional augmented data for 3 composers, Grieg, Mendelssohn, and Haydn\n* Introduction of noise to the images\n* A different NN model\n* Use of a pretrained image model like Resnet34 or Resnet50\n\n```\nResults for model 0\n              precision    recall  f1-score   support\n\n      mozart       0.63      0.68      0.66       651\n    schubert       0.52      0.52      0.52       727\n       grieg       0.35      0.21      0.26       133\n       haydn       0.37      0.42      0.39       246\n mendelssohn       0.22      0.26      0.24       133\n      chopin       0.56      0.50      0.52       458\n\n    accuracy                           0.52      2348\n   macro avg       0.44      0.43      0.43      2348\nweighted avg       0.52      0.52      0.51      2348\n```\n\n### Version 21 Results\n\n__________________________________________________________\n\n* 40 epochs\n* 3 way validation\n* Middle layers of NN used\n\nThe addition of the middle layers improved accuracy from 0.48 to 0.53. This was primarily due to a nice increase in both Grieg and Mendelssohn. \n\nBased on the train and validation accuracies, the model is overfitting. The next version will drop the epochs back to 25 to see if we can maintain similar accuracy. \n\n```\nResults for model 1\n              precision    recall  f1-score   support\n\n      mozart       0.66      0.70      0.68       651\n    schubert       0.52      0.54      0.53       727\n       grieg       0.26      0.20      0.22       133\n       haydn       0.44      0.51      0.47       246\n mendelssohn       0.26      0.30      0.28       133\n      chopin       0.56      0.44      0.49       458\n\n    accuracy                           0.53      2348\n   macro avg       0.45      0.45      0.45      2348\nweighted avg       0.53      0.53      0.53      2348\n```\n\n### Version 20 Results\n\n__________________________________________________________\n\n* 40 epochs\n* 3 way validation\n* Middle layers of NN not used\n\nThis serves as a baseline. We are predicting at a macro average of 0.48. However, both Grieg and Mendelssohn have far less entries so the data is unbalanced. These two composers are basically predicting the same as by chance. The prediction accuracy seems to be almost directly related to the number of samples available. \n\nNext iteration will add the middle layers back to see if that improves the result. \n\nFuture iterations will add more samples for Grieg, Haydn, and Mendelssohn.\n```\nResults for model 2\n              precision    recall  f1-score   support\n\n      mozart       0.63      0.61      0.62       651\n    schubert       0.49      0.51      0.50       727\n       grieg       0.18      0.20      0.19       133\n       haydn       0.35      0.42      0.38       246\n mendelssohn       0.26      0.10      0.14       133\n      chopin       0.49      0.49      0.49       458\n\n    accuracy                           0.48      2348\n   macro avg       0.40      0.39      0.39      2348\nweighted avg       0.48      0.48      0.48      2348\n```","metadata":{}},{"cell_type":"code","source":" \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Composer Identification Using a Neural Network\n\nThe purpose of this study is to determine how effective neural networks are in identifying and classifying classical music composers. ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport wave\nimport os\nimport IPython.display as ipd\n\nfrom IPython.display import Image, Audio\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:28.330699Z","iopub.execute_input":"2022-07-17T12:26:28.331787Z","iopub.status.idle":"2022-07-17T12:26:28.3375Z","shell.execute_reply.started":"2022-07-17T12:26:28.331681Z","shell.execute_reply":"2022-07-17T12:26:28.336832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the Pre-processed Data\n\nThere are prior notebooks which were used to prepare the base data for the model.\n\nThe primary input is a set of Mel spectrograms, which to a neural network are much like an image. \n\nWe read all the needed date from a set of pickle files. The datasets have already be split into training and test in a 70-30 ratio.","metadata":{}},{"cell_type":"code","source":"import pickle\n\ndef get_pkl (filename):\n\n    with open (filename,'rb') as inpf:\n        data = pickle.load (inpf)\n    return data    \n        \ninput_path = '../input/composer-classification-input/'\n#train_audio = get_pkl (input_path + 'train_audio.pkl')\n#test_audio = get_pkl (input_path + 'test_audio.pkl')\ntrain_spec = get_pkl (input_path + 'train_spec.pkl')\ntest_spec = get_pkl (input_path + 'test_spec.pkl')\nx_train = get_pkl (input_path + 'x_train.pkl')\ny_train = get_pkl (input_path + 'y_train.pkl')\nx_test = get_pkl (input_path + 'x_test.pkl')\ny_test = get_pkl (input_path + 'y_test.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:28.34673Z","iopub.execute_input":"2022-07-17T12:26:28.347397Z","iopub.status.idle":"2022-07-17T12:26:33.686845Z","shell.execute_reply.started":"2022-07-17T12:26:28.347354Z","shell.execute_reply":"2022-07-17T12:26:33.685947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nprint(sys.getsizeof(train_spec[0])) \na = 3.21\nsys.getsizeof(a)\ntype(a)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:33.688405Z","iopub.execute_input":"2022-07-17T12:26:33.688647Z","iopub.status.idle":"2022-07-17T12:26:33.69642Z","shell.execute_reply.started":"2022-07-17T12:26:33.688618Z","shell.execute_reply":"2022-07-17T12:26:33.695432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42) # setting a random seed\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:33.698208Z","iopub.execute_input":"2022-07-17T12:26:33.698676Z","iopub.status.idle":"2022-07-17T12:26:33.712295Z","shell.execute_reply.started":"2022-07-17T12:26:33.69863Z","shell.execute_reply":"2022-07-17T12:26:33.711095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look at the file sizes\nprint(len(train_spec))\nprint(len(test_spec))\ntrain_spec[0].shape\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:33.714569Z","iopub.execute_input":"2022-07-17T12:26:33.714971Z","iopub.status.idle":"2022-07-17T12:26:33.726132Z","shell.execute_reply.started":"2022-07-17T12:26:33.714932Z","shell.execute_reply":"2022-07-17T12:26:33.725258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at a few of the spectrograms.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pylab as plt\nimport seaborn as sns\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport pandas as pd\n\ndef display_audio (aud):\n    pd.Series(aud).plot(figsize=(10, 5),fontsize = 15,                           \n                  lw=1,\n                  title='Raw Audio Example',)\n                  #color=color_pal[0])\n    plt.show()\n\ndef display_spectrogram (S_db_mel):\n    fig, ax = plt.subplots(figsize=(10, 5))\n    # Plot the mel spectogram\n    img = librosa.display.specshow(S_db_mel,\n                                  x_axis='time',\n                                  y_axis='log',\n                                  ax=ax)\n    ax.set_title('Mel Spectogram Example', fontsize=15)\n    fig.colorbar(img, ax=ax, format=f'%0.2f')\n    plt.show()\n    \nfor i in range(5):\n    print (y_train[i])\n    #print (x_train[i])\n    display_spectrogram (train_spec[i])\n    #display_audio (train_audio[i])\n    #display_spectrogram (test_spec[i])  ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:33.728006Z","iopub.execute_input":"2022-07-17T12:26:33.72833Z","iopub.status.idle":"2022-07-17T12:26:35.512554Z","shell.execute_reply.started":"2022-07-17T12:26:33.728287Z","shell.execute_reply":"2022-07-17T12:26:35.511593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scale the Input Data\nNeural networks work better with scaled data, so we convert our spectrograms to scaled lists of numpy arrays.","metadata":{}},{"cell_type":"code","source":"\n#print (train_spec [0])\n\n# scale our data\nfrom sklearn.preprocessing import StandardScaler\n# define data\ndef scale_data (data):\n\n# define standard scaler\n    scaler = StandardScaler()\n\n# transform data\n    data_list = []\n    unscaled = False\n\n    for row in data:\n        if unscaled:\n            scaled = np.asarray(row)\n        else:    \n            scaled = scaler.fit_transform(np.asarray(row))\n        #scaled = scaled.astype(np.float16)\n        #print (scaled)\n        data_list.append(scaled)\n    return data_list\n\ntrain_spec_arr = scale_data(train_spec)\nprint (sys.getsizeof(train_spec_arr))\ntest_spec_arr = scale_data(test_spec)\n\na = test_spec_arr[0][0]\na","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:35.513879Z","iopub.execute_input":"2022-07-17T12:26:35.514157Z","iopub.status.idle":"2022-07-17T12:26:48.889404Z","shell.execute_reply.started":"2022-07-17T12:26:35.514126Z","shell.execute_reply":"2022-07-17T12:26:48.8885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Overfit Protection\n\nOur initial efforts showed that the model overfits the data producing less accurate validation and test results. Data augmentation is a possible solution.\n\nBecause the spectrogram is over a time period, a mirror image flip might be reasonable. Another possibility is to re-slice the initial data. The first group of slices were from [0:5000], [5000:10000] etc. The next set probably should be [2500:7500] etc.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The shape of the spectrogram is 256 by 216 which is 256 Mel scales and 216 time windows. \n\n* Input layer: 256 x 216 neurons (256 mel scales and 216 time windows)\n* Convolutional layer: 16 different 3 x 3 filters\n* Max pooling layer: 2 x 4\n* Convolutional layer: 32 different 3 x 3 filters\n* Max pooling layer: 2 x 4\n* Dense layer: 64 neurons\n* Output layer: 6 neurons for the 6 different composers","metadata":{}},{"cell_type":"code","source":"\ncomposer2num = {}\nnum2composer = {}\nour_composers = ['mozart','schubert','grieg','haydn','mendelssohn','chopin',]\nfor i, c in enumerate (our_composers):\n    composer2num[c] = i\n    num2composer[i] = c\ncomposer2num    ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:48.890537Z","iopub.execute_input":"2022-07-17T12:26:48.890767Z","iopub.status.idle":"2022-07-17T12:26:48.899582Z","shell.execute_reply.started":"2022-07-17T12:26:48.890731Z","shell.execute_reply":"2022-07-17T12:26:48.898682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Keras model\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.python.keras import callbacks\nfrom keras.layers import GaussianNoise\nfrom keras import regularizers\n\ndef build_cnn_model_ (inp):\n    model = models.Sequential()\n    model.add(layers.Conv2D(filters=128, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu,input_shape=inp))\n    model.add(layers.MaxPool2D((2, 2),strides=2))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Conv2D(filters=128, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(layers.MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Conv2D(filters=128, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(layers.MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Conv2D(filters=128, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(layers.MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Conv2D(filters=128, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(layers.MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Conv2D(filters=128, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(layers.MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(units=128, activation=tf.nn.relu,kernel_regularizer=tf.keras.regularizers.L2(0.003)))\n    model.add(layers.Dense(units=6, activation=tf.nn.softmax))\n    return model\n    \ndef build_cnn_model (inp):\n    filter_cnt = 32\n    model = Sequential()   \n    model.add(Conv2D(filters=filter_cnt, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu,input_shape=inp))\n    model.add(MaxPool2D((2, 2),strides=2))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(filters=filter_cnt, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(filters=filter_cnt, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(filters=filter_cnt, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(filters=filter_cnt, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    model.add(MaxPool2D(pool_size=(2, 2),strides=2))\n    model.add(Dropout(0.3))\n    #model.add(Conv2D(filters=filter_cnt, padding = \"same\", kernel_size=(5, 5), strides=(1, 1), activation=tf.nn.relu))\n    #model.add(MaxPool2D(pool_size=(2, 2),strides=2))\n    #model.add(Dropout(0.3))\n    model.add(Flatten())\n    model.add(Dense(units=128, activation=tf.nn.relu,kernel_regularizer=tf.keras.regularizers.L2(0.003)))\n    model.add(Dense(units=6, activation=tf.nn.softmax))\n    \n        # Define the optimizer\n    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n    \n    # Compile the model\n    model.compile(optimizer = optimizer , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model    \n\ndef build_model (inp):\n\n\n    model = Sequential()\n    #\n    model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n                     activation ='relu', kernel_regularizer=regularizers.l2(0.001), input_shape = inp))\n    model.add(GaussianNoise(0.05))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    # try adding some noise\n    model.add(Dropout(0.25))\n    # reduce the depth of the model for overfitting\n    if True:\n        model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu',kernel_regularizer=regularizers.l2(0.001),))\n        model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n        model.add(Dropout(0.25))\n    # fully connected\n    model.add(Flatten())\n#    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dense(256, activation = \"relu\",kernel_regularizer=regularizers.l2(0.001),))\n    model.add(Dropout(0.5))\n    model.add(Dense(6, activation = \"softmax\"))\n\n    # Define the optimizer\n    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n\n\n    # Compile the model\n    model.compile(optimizer = optimizer , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model\nes = callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='auto', restore_best_weights=True)\n\n# Callback for Reducing the Learning Rate... when the monitor levels out for 'patience' epochs, then the LR is reduced\nrlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5, min_lr=1e-6, mode='auto', verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:16:28.873831Z","iopub.execute_input":"2022-07-17T13:16:28.874356Z","iopub.status.idle":"2022-07-17T13:16:28.91624Z","shell.execute_reply.started":"2022-07-17T13:16:28.874307Z","shell.execute_reply":"2022-07-17T13:16:28.915505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This was some code I used in a previous competition.\n\nfor ifold, (idx_train, idx_val) in enumerate(cv.split(X = X, y = y)):\n\n        idx_train = idx_train\n        if NN_MODEL:\n            model = build_NN_model (X[idx_train].shape[1])\n            hist = model.fit(X[idx_train], y[idx_train],\n                validation_data=(X[idx_val], y[idx_val]), \n                callbacks=[es, ], epochs=150, batch_size=64)\n            val_preds = model.predict(X)\n            results.y_pred      = results.y_pred + val_preds.ravel()\n            val_preds_oof = model.predict(X[idx_val])\n            results.y_oof[idx_val] = val_preds_oof.ravel()\n            val_y_test = model.predict(X_test)     \n            results.y_test      = results.y_test + val_y_test.ravel()","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nprint (Counter(y_train))\nprint (Counter(y_test))","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:48.943377Z","iopub.execute_input":"2022-07-17T12:26:48.944161Z","iopub.status.idle":"2022-07-17T12:26:48.962168Z","shell.execute_reply.started":"2022-07-17T12:26:48.944112Z","shell.execute_reply":"2022-07-17T12:26:48.961044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"import numpy as np\nfrom PIL import Image\n\ndef PIL_resize(arr, s1, s2):\n\n    img = Image.fromarray(arr)\n    img.resize(size=(s1, s2))\n    return img\n    \nimg = train_spec_arr[0]\nimg_resized = PIL_resize(img, 128,128)\nimg_resized.shape","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\n\ndef PIL_resize(arr, s1, s2):\n\n    img = Image.fromarray(arr)\n    img = img.resize(size=(s1, s2))\n    return img\n    \ndef resize_list_to_array (data, s1, s2):\n\n    resized = [np.asarray(PIL_resize(i,s1,s2)) for i in data]\n    resized = np.asarray(resized)\n    return resized\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:48.965321Z","iopub.execute_input":"2022-07-17T12:26:48.96565Z","iopub.status.idle":"2022-07-17T12:26:48.973915Z","shell.execute_reply.started":"2022-07-17T12:26:48.965615Z","shell.execute_reply":"2022-07-17T12:26:48.972946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = resize_list_to_array (train_spec_arr, 128, 128)\nprint (X.shape)\nX = X.reshape(list(X.shape) + [1]) \nx_test = resize_list_to_array (test_spec_arr, 128, 128)\nx_test = x_test.reshape(list(x_test.shape) + [1])","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:48.97542Z","iopub.execute_input":"2022-07-17T12:26:48.975926Z","iopub.status.idle":"2022-07-17T12:26:55.214239Z","shell.execute_reply.started":"2022-07-17T12:26:48.975861Z","shell.execute_reply":"2022-07-17T12:26:55.213597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# because the compsitions are heavily weighted to mozart and schubert, we use the class_weight to help fit the model better\n# Sort artists by number of paintings\ncnumlist = [composer2num[c] for c in y_train]\nc_array = np.array(cnumlist)\nfrom sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced'\n                                               ,np.unique(c_array)\n                                               ,c_array)\nclass_weights = {i : class_weights[i] for i in range(6)}\nclass_weights\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:55.215349Z","iopub.execute_input":"2022-07-17T12:26:55.215675Z","iopub.status.idle":"2022-07-17T12:26:55.227617Z","shell.execute_reply.started":"2022-07-17T12:26:55.215646Z","shell.execute_reply":"2022-07-17T12:26:55.226957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nif True:\n    del train_spec_arr\n    #del train_audio\n    #del test_audio\n    del train_spec\n    del test_spec\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:26:55.228669Z","iopub.execute_input":"2022-07-17T12:26:55.229029Z","iopub.status.idle":"2022-07-17T12:26:55.552043Z","shell.execute_reply.started":"2022-07-17T12:26:55.228992Z","shell.execute_reply":"2022-07-17T12:26:55.550995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ny = []\nfor c in y_train:\n    y.append(composer2num[c])\ny = np.asarray(y)\n\nytest = []\nfor c in y_test:\n    ytest.append(composer2num[c])\nytest = np.asarray(ytest)\n\n#y[idx_train]\nprint (X.shape)\nprint (type(X))\nprint (type(y))\nfrom sklearn.model_selection import KFold\ncv = KFold(n_splits=3, shuffle=True)\nhistory_list = []\npred_list = []\n\n#results_y_oof  = np.zeros(len(X), y.dtype) + np.nan\n#results_y_pred = np.zeros(len(X), y.dtype)\n#results_y_test = np.zeros(len(test_spec_arr), y.dtype)\n#results_all_metric_oof  = []\n#results_all_metric_pred = []\n#results_loss_byfold = []\n\n# build only 1 model\nmodels = []\nfor ifold, (idx_train, idx_val) in enumerate(cv.split(X = x_train,y = y_train)):\n    print (len(idx_train))\n    if ifold < 11:\n        if ifold < 11:\n            model = build_cnn_model(X[idx_train].shape[1:] )\n        print(model.summary())\n        hist = model.fit(X[idx_train], y[idx_train],\n            validation_data=(X[idx_val], y[idx_val]), \n            callbacks=[es,rlr],             \n            epochs=100, batch_size=32, class_weight = class_weights)\n        val_preds = model.predict(X)\n        pred_list.append (val_preds)\n        #results_y_pred = results_y_pred + (val_preds.ravel())\n        #val_preds_oof = model.predict(X[idx_val])\n        #results_y_oof[idx_val] = val_preds_oof.ravel()\n        #val_y_test = model.predict(X_test)     \n        #    results.y_test      = results.y_test + val_y_test.ravel()\n        history_list.append(hist)\n        models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T12:52:41.435644Z","iopub.execute_input":"2022-07-17T12:52:41.436262Z","iopub.status.idle":"2022-07-17T13:14:58.252563Z","shell.execute_reply.started":"2022-07-17T12:52:41.436214Z","shell.execute_reply":"2022-07-17T13:14:58.251954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print (val_preds)\n\n# this converts probabilities into integers which identify the composer\n\nplist = []\nplisti = []\nfor p in pred_list:\n    plisti = []\n    for pp in p:\n        mx = np.argmax (pp)\n        plisti.append (mx)\n    plist.append (plisti)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tst_prd_prob = []\ntst_prd_list = []\ntst_prd = []\nfor m in models:\n    tst_prd_prob = []\n    test_preds = m.predict(x_test)\n    tst_prd_list.append (test_preds)\n    for t in test_preds:\n        mx = np.argmax (t)\n        tst_prd_prob.append (mx)\n    tst_prd.append(tst_prd_prob)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this computes an ensemble prediction\nplistarray = np.array(tst_prd_list)\nprint (plistarray[0][0])\nprint (plistarray[1][0])\nprint (plistarray[2][0])\nplistsum = plistarray[0] + plistarray[1] + plistarray[2]\nens_pred = []\nfor row in plistsum:\n    mx = np.argmax (row)\n    ens_pred.append (mx)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report\n\ndef print_confusion (y, pred, composers, title):\n    \n    cm = confusion_matrix (y, pred,)\n    np.set_printoptions(precision=2)\n\n\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                               display_labels=composers)\n    fig, ax = plt.subplots(figsize=(12,12))\n    ax.set_title('Confusion Matrix ' + title )\n    disp.plot(ax=ax)  \n\nfor i, p in enumerate(plist):\n    print ('Validation for fold ' + str(i))\n    print_confusion (y,p, our_composers, 'for fold ' + str(i))\n\nfor i, tp in enumerate(tst_prd):\n    print ('Results for model ' + str(i))\n    print_confusion(ytest, tp, our_composers, 'for model ' + str(i))\n    print(classification_report(ytest, tp, target_names=our_composers))\n    \nprint ('Confusion for Ensemble Prediction')\nprint_confusion(ytest, ens_pred, our_composers, 'for Ensemble ')\nprint(classification_report(ytest, ens_pred, target_names=our_composers))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.metrics import classification_report\n\n#print(classification_report(ytest, tst_prd, target_names=our_composers))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hist.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(hist):\n    \n    plt.figure(figsize=(5,4))\n    fig, axs = plt.subplots(2)\n    \n    # accuracy subplot\n    axs[0].plot(hist.history[\"accuracy\"], label=\"train accuracy\")\n    axs[0].plot(hist.history[\"val_accuracy\"], label=\"validation/test accuracy\")    \n    axs[0].set_ylabel(\"Accuracy\")\n    axs[0].legend(loc=\"lower right\")\n    axs[0].set_title(\"Accuracy eval\")\n    \n    # Error subplot\n    axs[1].plot(hist.history[\"loss\"], label=\"train error\")\n    axs[1].plot(hist.history[\"val_loss\"], label=\"test error\")    \n    axs[1].set_ylabel(\"Error\")\n    axs[1].set_xlabel(\"Epoch\")\n    axs[1].legend(loc=\"upper right\")\n    axs[1].set_title(\"Error eval\")\n    \n    plt.show()\n\nfor hist in history_list:    \n    plot_history (hist)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert to Audio Display","metadata":{}},{"cell_type":"markdown","source":"## Build a Sample Mel Spectrogram","metadata":{}},{"cell_type":"code","source":"#np.random.shuffle(all_midis) # shuffle our dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}